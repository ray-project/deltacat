{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Shard Demo: Processing and Analyzing Data with DeltaCat\n",
    "\n",
    "This example showcases how DeltaCat simplifies dataset management, enabling seamless integration with PyTorch and distributed frameworks like Ray for scalable data processing.\n",
    "\n",
    "**Steps in the Demo:**\n",
    "- **Generate Data:** Create a Parquet file with fake contact information, including `id`, `name`, `age`, and `score`.\n",
    "- **Load Dataset:** Use DeltaCat to load the data from the Parquet file into a `Dataset`.\n",
    "- **Shard Data:** Split the dataset into multiple shards for parallel processing.\n",
    "- **Distributed Processing:** Use Ray to process each shard in parallel, calculating total age and count for each shard.\n",
    "- **Aggregate Results:** Combine results from all shards to compute the overall average age."
   ],
   "id": "ed4589793858977c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import Tuple, Generator, List\n",
    "import deltacat as dc\n",
    "import pathlib\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import ray\n",
    "from faker import Faker\n",
    "import random\n",
    "import string\n",
    "\n",
    "ray.init()"
   ],
   "id": "a9bae3a650312f1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parquet_file_path = pathlib.Path.cwd() / \"data.parquet\"\n",
    "\n",
    "# for string id try changing char_pool to string.ascii_letters\n",
    "# this method of generation isn't consistent and you may or may not see a uniform distribution.\n",
    "def generate_random_id(length=10, char_pool=string.digits):\n",
    "    return ''.join(random.choices(char_pool, k=length))\n",
    "\n",
    "fake = Faker()\n",
    "num_records = 10000\n",
    "\n",
    "# Try playing around with the different ID generators below.\n",
    "# You should observe a difference in the distribution of id's over shards.\n",
    "data = {\n",
    "    \"id\": range(1, num_records + 1),\n",
    "    # \"id\": [generate_random_id(char_pool=string.ascii_letters) for _ in range(num_records)],\n",
    "    # \"id\": [fake.uuid4() for _ in range(num_records)],\n",
    "    \"name\": [fake.name() for _ in range(num_records)],\n",
    "    \"age\": [random.randint(18, 80) for _ in range(num_records)],\n",
    "    \"score\": [random.randint(0, 100) for _ in range(num_records)]\n",
    "}\n",
    "\n",
    "table = pa.Table.from_pydict(data)\n",
    "pq.write_table(table, parquet_file_path)\n",
    "print(f\"Created Parquet file at: {parquet_file_path}\")"
   ],
   "id": "a7a0a8377d61284d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = dc.Dataset.from_parquet(\n",
    "    name=\"data\",\n",
    "    file_uri=parquet_file_path,\n",
    "    metadata_uri=\".\",\n",
    "    merge_keys=\"id\"\n",
    ")\n",
    "print(\"Loaded dataset from Parquet file.\")\n",
    "dataset.print(num_records=10)"
   ],
   "id": "b35bbd7ce1274b5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "shards = dataset.shards(num_shards=10)\n",
    "print(len(shards))\n",
    "print(shards)"
   ],
   "id": "f90eb8028fe8f7fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@ray.remote\n",
    "def process_shard(shard: Generator[torch.Tensor, None, None], fields: List[str]) -> Tuple[float, int]:\n",
    "    tensor_generator = dataset.scan(shard=shard, fields=fields).to_tensor()\n",
    "    total_age = 0.0\n",
    "    count = 0\n",
    "\n",
    "    # calculate total\n",
    "    for tensor in tensor_generator:\n",
    "        ages = tensor[:, 0]\n",
    "        total_age += ages.sum().item()\n",
    "        count += 1\n",
    "\n",
    "    return total_age, count\n",
    "\n",
    "# you can pick fields to include here.\n",
    "# fields must be numerical since we want to generate tensors.\n",
    "fields_to_include = [\"age\"]\n",
    "futures = [process_shard.remote(shard, fields=fields_to_include) for shard in shards]\n",
    "results = ray.get(futures)\n"
   ],
   "id": "cb106026654c94f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aggregate results from all shards\n",
    "total_age = 0.0\n",
    "total_count = 0\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    shard_total_age, shard_count = result\n",
    "    print(f\"[Shard {idx}] total count: {shard_count}, total age: {shard_total_age}\")\n",
    "    total_age += shard_total_age\n",
    "    total_count += shard_count\n",
    "\n",
    "if total_count > 0:\n",
    "    average_age = total_age / total_count\n",
    "    print(f\"Average age across all shards: {average_age}\")\n",
    "else:\n",
    "    print(\"No data available to compute average age.\")"
   ],
   "id": "6203d9c400092ddf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
